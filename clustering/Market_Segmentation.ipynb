{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0"
      },
      "source": [
        "# Beer Brand Clustering Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1"
      },
      "source": [
        "## 1. Introduction & Business Objectives\n",
        "\n",
        "This analysis performs customer segmentation on beer brands based on their nutritional and pricing characteristics. The primary objectives are:\n",
        "\n",
        "- **Market Segmentation**: Group beer brands into distinct segments based on product attributes\n",
        "- **Product Positioning**: Understand how different brands position themselves in the market\n",
        "- **Strategic Insights**: Identify gaps and opportunities in the beer market\n",
        "\n",
        "**Key Business Questions:**\n",
        "- What natural groupings exist among beer brands?\n",
        "- Which product attributes drive market segmentation?\n",
        "- How can brands optimize their positioning strategy?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2"
      },
      "source": [
        "## 2. Data Loading & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
        "from sklearn.feature_selection import f_classif\n",
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4"
      },
      "source": [
        "## 3. Data Dictionary\n",
        "\n",
        "| Column | Description | Unit | Business Relevance |\n",
        "|--------|-------------|------|--------------------|\n",
        "| **name** | Beer brand name | Text | Brand identifier |\n",
        "| **calories** | Caloric content per serving | kcal | Health-conscious positioning |\n",
        "| **sodium** | Sodium content | mg | Health/dietary considerations |\n",
        "| **alcohol** | Alcohol by volume | % | Strength positioning |\n",
        "| **cost** | Price per unit | USD | Value positioning |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5"
      },
      "source": [
        "## 4. Data Preparation & Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6"
      },
      "outputs": [],
      "source": [
        "def load_and_explore_data(file_path):\n",
        "    \"\"\"\n",
        "    Load beer dataset and display basic information.\n",
        "\n",
        "    Parameters:\n",
        "    file_path (str): Path to the CSV file\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: Loaded dataset\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    print(f\"Dataset Shape: {df.shape}\")\n",
        "    print(f\"Missing Values: {df.isnull().sum().sum()}\")\n",
        "    print(\"\\nDataset Overview:\")\n",
        "    print(df.describe())\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7"
      },
      "outputs": [],
      "source": [
        "beer_df = load_and_explore_data(\"beer.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "beer_df"
      ],
      "metadata": {
        "id": "8VGXT-F-xpyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8"
      },
      "outputs": [],
      "source": [
        "def prepare_clustering_data(df, features):\n",
        "    \"\"\"\n",
        "    Scale features for clustering analysis.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): Input dataset\n",
        "    features (list): List of feature columns to scale\n",
        "\n",
        "    Returns:\n",
        "    tuple: (scaled_data, scaler_object)\n",
        "    \"\"\"\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(df[features])\n",
        "    scaled_df = pd.DataFrame(scaled_data, columns=features, index=df.index)\n",
        "\n",
        "    print(\"Feature scaling completed using Min-Max normalization\")\n",
        "    print(f\"Scaled data shape: {scaled_df.shape}\")\n",
        "\n",
        "    return scaled_df, scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9"
      },
      "outputs": [],
      "source": [
        "clustering_features = ['calories', 'sodium', 'alcohol', 'cost']\n",
        "scaled_beer_df, scaler = prepare_clustering_data(beer_df, clustering_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a10"
      },
      "source": [
        "## 5. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a11"
      },
      "outputs": [],
      "source": [
        "def create_exploratory_plots(df):\n",
        "    \"\"\"\n",
        "    Create exploratory scatter plots to understand data relationships.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): Input dataset\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # Alcohol vs Calories\n",
        "    sns.scatterplot(data=df, x='alcohol', y='calories', ax=axes[0], s=80, alpha=0.7)\n",
        "    axes[0].set_title('Beer Positioning: Alcohol Content vs Caloric Value',\n",
        "                     fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('Alcohol Content (%)', fontsize=12)\n",
        "    axes[0].set_ylabel('Calories per Serving (kcal)', fontsize=12)\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Alcohol vs Cost\n",
        "    sns.scatterplot(data=df, x='alcohol', y='cost', ax=axes[1], s=80, alpha=0.7)\n",
        "    axes[1].set_title('Market Positioning: Alcohol Content vs Price Point',\n",
        "                     fontsize=14, fontweight='bold')\n",
        "    axes[1].set_xlabel('Alcohol Content (%)', fontsize=12)\n",
        "    axes[1].set_ylabel('Price per Unit (USD)', fontsize=12)\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a12"
      },
      "outputs": [],
      "source": [
        "create_exploratory_plots(beer_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a13"
      },
      "source": [
        "## 6. Clustering Analysis\n",
        "\n",
        "### Optimal Cluster Selection using Elbow Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a14"
      },
      "outputs": [],
      "source": [
        "def find_optimal_clusters(scaled_data, max_clusters=10):\n",
        "    \"\"\"\n",
        "    Use elbow method to find optimal number of clusters.\n",
        "\n",
        "    Parameters:\n",
        "    scaled_data (pd.DataFrame): Scaled feature data\n",
        "    max_clusters (int): Maximum number of clusters to test\n",
        "\n",
        "    Returns:\n",
        "    dict: Dictionary with cluster range and corresponding inertia values\n",
        "    \"\"\"\n",
        "    cluster_range = range(1, max_clusters + 1)\n",
        "    inertia_values = []\n",
        "\n",
        "    for k in cluster_range:\n",
        "        kmeans = KMeans(n_clusters=k,\n",
        "                        random_state=42,\n",
        "                        n_init=10)\n",
        "\n",
        "        kmeans.fit(scaled_data)\n",
        "        inertia_values.append(kmeans.inertia_)\n",
        "\n",
        "    # Create elbow plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(cluster_range,\n",
        "             inertia_values,\n",
        "             marker='o',\n",
        "             linewidth=2,\n",
        "             markersize=8,\n",
        "             color = 'red')\n",
        "\n",
        "    plt.title('Elbow Method for Optimal Cluster Selection',\n",
        "              fontsize=16,\n",
        "              fontweight='bold')\n",
        "\n",
        "    plt.xlabel('Number of Clusters (k)',\n",
        "               fontsize=12)\n",
        "\n",
        "    plt.ylabel('Within-Cluster Sum of Squares (WCSS)',\n",
        "               fontsize=12)\n",
        "\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(cluster_range)\n",
        "\n",
        "    # Annotate potential elbow points\n",
        "    for i, txt in enumerate(inertia_values):\n",
        "        plt.annotate(f'{txt:.2f}', (cluster_range[i], inertia_values[i]),\n",
        "                    textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return {'cluster_range': list(cluster_range), 'inertia_values': inertia_values}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a15"
      },
      "outputs": [],
      "source": [
        "elbow_results = find_optimal_clusters(scaled_beer_df, max_clusters=9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a16"
      },
      "source": [
        "## 7. Model Evaluation\n",
        "\n",
        "### Silhouette Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a17"
      },
      "outputs": [],
      "source": [
        "def visualize_silhouette_analysis(scaled_data, k_values=[2, 3, 4, 5]):\n",
        "    \"\"\"\n",
        "    Create silhouette visualizations for different cluster numbers using Yellowbrick.\n",
        "\n",
        "    Parameters:\n",
        "    scaled_data (pd.DataFrame): Scaled feature data\n",
        "    k_values (list): List of k values to evaluate\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: Silhouette scores for each k value\n",
        "    \"\"\"\n",
        "    n_clusters = len(k_values)\n",
        "    n_cols = 2\n",
        "    n_rows = (n_clusters + n_cols - 1) // n_cols\n",
        "\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
        "    axes = axes.flatten() if n_clusters > 1 else [axes]\n",
        "\n",
        "    silhouette_results = []\n",
        "\n",
        "    print(\"Silhouette Analysis Results:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    for i, k in enumerate(k_values):\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "\n",
        "        # Create silhouette visualizer\n",
        "        visualizer = SilhouetteVisualizer(\n",
        "            kmeans,\n",
        "            colors='yellowbrick',\n",
        "            ax=axes[i]\n",
        "        )\n",
        "\n",
        "        # Fit the visualizer and the model\n",
        "        visualizer.fit(scaled_data)\n",
        "\n",
        "        # Get silhouette score\n",
        "        sil_score = visualizer.silhouette_score_\n",
        "        silhouette_results.append({\n",
        "            'n_clusters': k,\n",
        "            'silhouette_score': sil_score\n",
        "        })\n",
        "\n",
        "        # Customize the plot\n",
        "        axes[i].set_title(f'Silhouette Analysis (k={k}, score={sil_score:.3f})',\n",
        "                         fontsize=12, fontweight='bold')\n",
        "\n",
        "        print(f\"k = {k:2d} | Silhouette Score: {sil_score:.3f}\")\n",
        "\n",
        "    # Hide empty subplots\n",
        "    for j in range(n_clusters, len(axes)):\n",
        "        axes[j].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return pd.DataFrame(silhouette_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a18"
      },
      "outputs": [],
      "source": [
        "# Perform silhouette analysis with visualizations\n",
        "silhouette_results = visualize_silhouette_analysis(scaled_beer_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_calinski_harabasz_scores(scaled_data, k_values=[2, 3, 4, 5]):\n",
        "    \"\"\"\n",
        "    Calculate Calinski-Harabasz scores for different cluster numbers.\n",
        "\n",
        "    Parameters:\n",
        "    scaled_data (pd.DataFrame): Scaled feature data\n",
        "    k_values (list): List of k values to evaluate\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: Calinski-Harabasz scores for each k value\n",
        "    \"\"\"\n",
        "    ch_results = []\n",
        "\n",
        "    print(\"\\nCalinski-Harabasz Index Results:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    for k in k_values:\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "        labels = kmeans.fit_predict(scaled_data)\n",
        "\n",
        "        ch_score = calinski_harabasz_score(scaled_data, labels)\n",
        "        ch_results.append({\n",
        "            'n_clusters': k,\n",
        "            'calinski_harabasz_score': ch_score,\n",
        "            'inertia': kmeans.inertia_\n",
        "        })\n",
        "\n",
        "        print(f\"k = {k:2d} | Calinski-Harabasz Score: {ch_score:.2f}\")\n",
        "\n",
        "    # Create visualization\n",
        "    ch_df = pd.DataFrame(ch_results)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(ch_df['n_clusters'], ch_df['calinski_harabasz_score'],\n",
        "             marker='o', linewidth=2, markersize=8, color='darkgreen')\n",
        "    plt.title('Calinski-Harabasz Index by Number of Clusters',\n",
        "              fontsize=16, fontweight='bold')\n",
        "    plt.xlabel('Number of Clusters (k)', fontsize=12)\n",
        "    plt.ylabel('Calinski-Harabasz Index', fontsize=12)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(k_values)\n",
        "\n",
        "    # Annotate points\n",
        "    for i, row in ch_df.iterrows():\n",
        "        plt.annotate(f'{row[\"calinski_harabasz_score\"]:.1f}',\n",
        "                    (row['n_clusters'], row['calinski_harabasz_score']),\n",
        "                    textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return ch_df"
      ],
      "metadata": {
        "id": "s7GKp7sqjXWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Calinski-Harabasz scores\n",
        "ch_results = calculate_calinski_harabasz_scores(scaled_beer_df)\n",
        "\n",
        "# Combine results\n",
        "performance_results = pd.merge(silhouette_results, ch_results, on='n_clusters')\n",
        "print(\"\\nCombined Performance Results:\")\n",
        "performance_results"
      ],
      "metadata": {
        "id": "xS1CUk6Jw3_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a19"
      },
      "source": [
        "### Final Model Selection and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a20"
      },
      "outputs": [],
      "source": [
        "def train_final_model(scaled_data, n_clusters):\n",
        "    \"\"\"\n",
        "    Train the final clustering model with specified number of clusters.\n",
        "\n",
        "    Parameters:\n",
        "    scaled_data (pd.DataFrame): Scaled feature data\n",
        "    n_clusters (int): Number of clusters\n",
        "\n",
        "    Returns:\n",
        "    KMeans: Trained clustering model\n",
        "    \"\"\"\n",
        "    final_model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "    cluster_labels = final_model.fit_predict(scaled_data)\n",
        "\n",
        "    print(f\"Final model trained with {n_clusters} clusters\")\n",
        "    print(f\"Cluster distribution: {np.bincount(cluster_labels)}\")\n",
        "\n",
        "    return final_model, cluster_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a21"
      },
      "outputs": [],
      "source": [
        "optimal_k = 5\n",
        "final_model, cluster_labels = train_final_model(scaled_beer_df, optimal_k)\n",
        "beer_df['cluster_id'] = cluster_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a25"
      },
      "source": [
        "## 8. Cluster Profiling\n",
        "\n",
        "### Cluster Characteristics Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a26"
      },
      "outputs": [],
      "source": [
        "def analyze_cluster_profiles(df, cluster_col='cluster_id', features=None):\n",
        "    \"\"\"\n",
        "    Create detailed profiles for each cluster.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): Dataset with cluster assignments\n",
        "    cluster_col (str): Name of cluster column\n",
        "    features (list): List of features to analyze\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: Cluster profiles\n",
        "    \"\"\"\n",
        "    if features is None:\n",
        "        features = ['calories', 'sodium', 'alcohol', 'cost']\n",
        "\n",
        "    cluster_profiles = df.groupby(cluster_col)[features].agg(['mean', 'std', 'count']).round(2)\n",
        "\n",
        "    print(\"Cluster Profiles Summary:\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    for cluster_id in sorted(df[cluster_col].unique()):\n",
        "        cluster_data = df[df[cluster_col] == cluster_id]\n",
        "        print(f\"\\nCluster {cluster_id} ({len(cluster_data)} brands):\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        for feature in features:\n",
        "            mean_val = cluster_data[feature].mean()\n",
        "            print(f\"{feature.capitalize():12}: {mean_val:.2f} (avg)\")\n",
        "\n",
        "        print(f\"Brands: {', '.join(cluster_data['name'].tolist())}\")\n",
        "\n",
        "    return cluster_profiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a27"
      },
      "outputs": [],
      "source": [
        "cluster_profiles = analyze_cluster_profiles(beer_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a22"
      },
      "source": [
        "### Feature Importance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a23"
      },
      "outputs": [],
      "source": [
        "def analyze_feature_importance(scaled_data, cluster_labels):\n",
        "    \"\"\"\n",
        "    Analyze which features contribute most to cluster separation.\n",
        "\n",
        "    Parameters:\n",
        "    scaled_data (pd.DataFrame): Scaled feature data\n",
        "    cluster_labels (array): Cluster assignments\n",
        "\n",
        "    Returns:\n",
        "    pd.Series: Feature importance scores\n",
        "    \"\"\"\n",
        "    f_scores, p_values = f_classif(scaled_data, cluster_labels)\n",
        "    importance_df = pd.DataFrame({\n",
        "        'feature': scaled_data.columns,\n",
        "        'f_score': f_scores,\n",
        "        'p_value': p_values\n",
        "    }).sort_values('f_score', ascending=False)\n",
        "\n",
        "    # Create importance plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    bars = plt.bar(importance_df['feature'], importance_df['f_score'],\n",
        "                   color='skyblue', edgecolor='navy', alpha=0.7)\n",
        "    plt.title('Feature Importance for Cluster Separation',\n",
        "              fontsize=16, fontweight='bold')\n",
        "    plt.xlabel('Features', fontsize=12)\n",
        "    plt.ylabel('F-Score', fontsize=12)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar, score in zip(bars, importance_df['f_score']):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.5,\n",
        "                f'{score:.1f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "    plt.grid(True, alpha=0.3, axis='y')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return importance_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a24"
      },
      "outputs": [],
      "source": [
        "feature_importance = analyze_feature_importance(scaled_beer_df, cluster_labels)\n",
        "print(\"\\nFeature Importance Ranking:\")\n",
        "print(feature_importance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a28"
      },
      "source": [
        "### Cluster Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a29"
      },
      "outputs": [],
      "source": [
        "def create_cluster_distribution_plots(df, features, cluster_col='cluster_id'):\n",
        "    \"\"\"\n",
        "    Create distribution plots for each feature by cluster.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): Dataset with cluster assignments\n",
        "    features (list): List of features to plot\n",
        "    cluster_col (str): Name of cluster column\n",
        "    \"\"\"\n",
        "    n_features = len(features)\n",
        "    n_cols = 2\n",
        "    n_rows = (n_features + n_cols - 1) // n_cols\n",
        "\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
        "    axes = axes.flatten() if n_features > 1 else [axes]\n",
        "\n",
        "    for i, feature in enumerate(features):\n",
        "        #sns.kdeplot(data=df, x=feature, hue=cluster_col, ax=axes[i],\n",
        "        #           fill=True, alpha=0.6, linewidth=2)\n",
        "        sns.boxplot(data=df, y=feature, x=cluster_col, ax=axes[i])\n",
        "        axes[i].set_title(f'{feature.capitalize()} Distribution by Cluster',\n",
        "                         fontsize=14, fontweight='bold')\n",
        "        axes[i].set_ylabel(f'{feature.capitalize()}', fontsize=12)\n",
        "        axes[i].set_xlabel('Cluster IDs', fontsize=12)\n",
        "        axes[i].grid(True, alpha=0.3)\n",
        "        axes[i].legend(title='Cluster', title_fontsize=10)\n",
        "\n",
        "    # Hide empty subplots\n",
        "    for j in range(n_features, len(axes)):\n",
        "        axes[j].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a30"
      },
      "outputs": [],
      "source": [
        "create_cluster_distribution_plots(beer_df, clustering_features)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fPk7sHjoxJmz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}